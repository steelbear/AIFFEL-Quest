{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d01131b",
   "metadata": {},
   "source": [
    "# 1. 모델과 토크나이저 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78be7f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook is running on cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "import numpy\n",
    "\n",
    "# 사용하는 연산장치 확인\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"This notebook is running on\", device)\n",
    "\n",
    "# huggingface를 통해 모델과 토크나이저 불러오기\n",
    "model_name = \"skt/ko-gpt-trinity-1.2B-v0.5\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3d637b",
   "metadata": {},
   "source": [
    "## 토크나이저 확인하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7d8f335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt2': 1024,\n",
       " 'gpt2-medium': 1024,\n",
       " 'gpt2-large': 1024,\n",
       " 'gpt2-xl': 1024,\n",
       " 'distilgpt2': 1024}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 파라미터 크기별 사용하는 토큰 수 확인하기\n",
    "tokenizer.max_model_input_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5556056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 문장\n",
    "input_txt = \"바람도 없는 공중에 수직의 파문을 내이며 고요히 떨어지는 오동잎은 누구의 발자취 입니까.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c704b17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 토큰화\n",
    "tokens = tokenizer(input_txt).tokens()\n",
    "\n",
    "# 토큰 정수화\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6f3ee71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kogpt-2_tokens</th>\n",
       "      <td>▁바람</td>\n",
       "      <td>도</td>\n",
       "      <td>▁없는</td>\n",
       "      <td>▁공</td>\n",
       "      <td>중에</td>\n",
       "      <td>▁수직</td>\n",
       "      <td>의</td>\n",
       "      <td>▁파</td>\n",
       "      <td>문을</td>\n",
       "      <td>▁내</td>\n",
       "      <td>이며</td>\n",
       "      <td>▁고요</td>\n",
       "      <td>히</td>\n",
       "      <td>▁떨어지는</td>\n",
       "      <td>▁오</td>\n",
       "      <td>동</td>\n",
       "      <td>잎</td>\n",
       "      <td>은</td>\n",
       "      <td>▁누구</td>\n",
       "      <td>의</td>\n",
       "      <td>▁발자</td>\n",
       "      <td>취</td>\n",
       "      <td>▁입</td>\n",
       "      <td>니까.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input_IDs</th>\n",
       "      <td>31140</td>\n",
       "      <td>20780</td>\n",
       "      <td>30359</td>\n",
       "      <td>30016</td>\n",
       "      <td>31373</td>\n",
       "      <td>41427</td>\n",
       "      <td>25792</td>\n",
       "      <td>30163</td>\n",
       "      <td>31047</td>\n",
       "      <td>30024</td>\n",
       "      <td>31111</td>\n",
       "      <td>51068</td>\n",
       "      <td>29936</td>\n",
       "      <td>36152</td>\n",
       "      <td>30027</td>\n",
       "      <td>20801</td>\n",
       "      <td>25846</td>\n",
       "      <td>25768</td>\n",
       "      <td>31199</td>\n",
       "      <td>25792</td>\n",
       "      <td>44202</td>\n",
       "      <td>27472</td>\n",
       "      <td>30148</td>\n",
       "      <td>37708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0      1      2      3      4      5      6      7      8   \\\n",
       "kogpt-2_tokens    ▁바람      도    ▁없는     ▁공     중에    ▁수직      의     ▁파     문을   \n",
       "Input_IDs       31140  20780  30359  30016  31373  41427  25792  30163  31047   \n",
       "\n",
       "                   9      10     11     12     13     14     15     16     17  \\\n",
       "kogpt-2_tokens     ▁내     이며    ▁고요      히  ▁떨어지는     ▁오      동      잎      은   \n",
       "Input_IDs       30024  31111  51068  29936  36152  30027  20801  25846  25768   \n",
       "\n",
       "                   18     19     20     21     22     23  \n",
       "kogpt-2_tokens    ▁누구      의    ▁발자      취     ▁입    니까.  \n",
       "Input_IDs       31199  25792  44202  27472  30148  37708  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰과 해당하는 정수값 매칭을 DataFrame으로 보여주기\n",
    "pd.options.display.max_columns = 40\n",
    "pd.options.display.max_rows = 60\n",
    "df = pd.DataFrame([tokens, input_ids[0]], index=[\"kogpt-2_tokens\", \"Input_IDs\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e629c6e",
   "metadata": {},
   "source": [
    "## 모델 디코딩 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "279ae94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "바람도 없는 공중에 수직의 파문을 내이며 고요히 떨어지는 오동잎은 누구의 발자취 입니까. 이 세상 어디에도 당신과 나는 같은 사람은 없읍니다. \n",
      " \n",
      " 사랑한다는 것은 \n",
      " 그대와 나, 둘만이 알수 있는 \n",
      " 세상에서 가장 잔인한 약속입니다. \n",
      " 내가 이 세상에서 사랑한 사람은 \n",
      " 오직 당신뿐인것을 \n",
      " 그대에게 전할 수 없는 이 마음..... \n",
      " 이 세상에 나만이 그대를 사랑할수 있을것 같은 \n",
      " 이런 착각에 빠져 \n",
      " 살며시 눈감아도 그대의 그림자는 나를 따릅니다. \n",
      " 내 눈가에 눈물 한방울이 떨어져도 \n",
      " 나의 마음엔 그\n"
     ]
    }
   ],
   "source": [
    "# 예제 문장 토큰화\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "\n",
    "# Beam Search Decoding\n",
    "max_length = 128\n",
    "output_beam = model.generate(input_ids, # 입력 시퀀스\n",
    "                             max_length=max_length, # 생성 시퀀스 최대 길이\n",
    "                             num_beams=7, # Beam Search할 범위\n",
    "                             no_repeat_ngram_size=2, # 지정된 ngram 단위로 중복 체크\n",
    "                             do_sample=True, # 토큰 샘플링\n",
    "                             temperature=2.0, # 토큰 결정시 확률 반영도\n",
    "                             top_k=50, # 후보 토큰 고를시 높은 확률순 k위까지만 보고 결정\n",
    "                            )\n",
    "\n",
    "# beam search로 만들어진 문장중 하나 출력\n",
    "print(tokenizer.decode(output_beam[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a3917b",
   "metadata": {},
   "source": [
    "# 2. 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10cc05d",
   "metadata": {},
   "source": [
    "## SFT(Supervised Fine-Tuning) 데이터셋 \n",
    "- prompt\n",
    "    - 사용자가 올릴 질문\n",
    "- completion\n",
    "    - 모델이 생성해야할 답변\n",
    "- tokens\n",
    "    - 총 토큰 수로 추정\n",
    "    - KoChatGPT가 학습할 때 사용할 tokenizer 기준으로 보임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbd6255c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFT 데이터셋 크기: 12000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': '불고기용 고기 한우에요?',\n",
       "  'completion': \"'저는 인공지능 챗봇이며, 직접적으로 식품에 관한 정보를 가지고 있지 않습니다. 하지만 일반적으로 불고기용 고기는 한우, 쇠고기, 돼지고기 등 다양한 종류의 고기를 사용합니다. 하지만 한우는 대표적인 고급 육류로 알려져 있기 때문에, 한우를 사용하는 경우도 많습니다. 알러지나 개별 건강 상태에 따라 다를 수 있으니 충분한 정보 수집 후에 선택해 주시기 바랍니다.\",\n",
       "  'tokens': 193},\n",
       " {'prompt': '쓰던 앱이 유료로 전환됐어',\n",
       "  'completion': \"'어떤 앱인지 모르기 때문에 정확한 답변을 드리기 어렵습니다. 하지만, 일반적으로 유료 전환된 앱은 기존 무료 앱에서 추가적인 기능이나 서비스를 제공하는 경우가 많습니다. 이 경우, 유료 전환 이전 가격이 매우 저렴하거나 무료인 경우가 많으므로, 앱을 계속 사용하려면 추가적인 비용을 지불해야 할 수 있습니다. 하지만, 유료 전환 이후에는 기존 사용자 또는 새로운 사용자 모두가 추가 기능과 높은 품질의 서비스를 이용할 수 있게 됩니다. 따라서, 앱 개발자는 유료 모델로 전환함으로써 앱의 수익을 증가시키고 더 나은 서비스를 제공할 수 있습니다.\",\n",
       "  'tokens': 288},\n",
       " {'prompt': '여친이랑 다툼',\n",
       "  'completion': \"'저는 인공지능이기 때문에 여친과의 다툼에 대해서는 조언을 드릴 수는 없습니다. 하지만 다투게 되면 상대방의 말을 경청하는 태도와 서로의 감정을 존중하는 것이 중요합니다. 논리적이고 차분한 대화를 통해 문제를 해결해보세요. 그리고 서로를 이해하고 서로의 의견을 수용하는 것이 중요합니다.\",\n",
       "  'tokens': 153}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json \n",
    "\n",
    "HOME_DIR = os.getenv('HOME')\n",
    "\n",
    "data_path_1_SFT = HOME_DIR + '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_1_SFT.jsonl' \n",
    "with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "# SFT 데이터셋 크기\n",
    "print('SFT 데이터셋 크기:', len(list_data_dict))\n",
    "\n",
    "# SFT 데이터셋 확인하기\n",
    "list_data_dict[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78db28d9",
   "metadata": {},
   "source": [
    "## RM (Reward Model) 데이터셋\n",
    "- prompt\n",
    "    - 사용자가 올릴 질문\n",
    "- completion_0, completion_1, completion_2\n",
    "    - 각 모델별 답변\n",
    "        - ChatGPT\n",
    "        - GPT3(Ada)\n",
    "        - GPT3(Davinci)\n",
    "    - 어떤 답변이 어떤 모델로 생성됐는지 알수 없도록 답변 순서를 섞음\n",
    "- ranking\n",
    "    - 사람이 라벨링한 각 답변의 품질 랭킹\n",
    "    - 값이 낮을수록 높은 품질"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "566de5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RM 데이터셋 크기: 10220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': '번디는 자신이 탐정잡지, 범죄소설 그리고 성범죄 관련 실제 범죄 다큐멘터리들을 탐독했다고 누구에게 말했나?',\n",
       "  'completion_0': 'Allow me to answer your question. I know that you are curious about me.',\n",
       "  'completion_1': '번디는 다양한 인터뷰자들과 뉴스홍보 담당자들과의 면담 때 밝혔다.',\n",
       "  'completion_2': '라이언에게 말했다.',\n",
       "  'ranking': [2, 1, 0]},\n",
       " {'prompt': '개포주공아파트는 몇 단지로 이루어져 있나?',\n",
       "  'completion_0': '개포주공아파트는 다섯 단지로 이루어져 있습니다.',\n",
       "  'completion_1': '이날 목송에서 구글상위노',\n",
       "  'completion_2': '개포주공아파트는 총 27개 단지로 이루어져 있습니다.',\n",
       "  'ranking': [2, 0, 1]},\n",
       " {'prompt': '김영삼의 후보 시절 지역표심을 겨냥한 발언을 문제삼은 후보는?',\n",
       "  'completion_0': 'The diameter of the Metallic domain is bigger than the Hyperonic domain.',\n",
       "  'completion_1': '이 질문은 조금 불분명합니다. 김영삼 대통령이 후보 시절에 어떤 발언을 했고, 누가 그 발언을 문제삼았는지에 따라 답이 다를 수 있습니다.\\\\n\\\\n만약 김영삼 대통령이 후보 시절에 지역표심을 겨냥한 발언을 했다는 가정하에, 그 발언을 문제삼은 후보가 누구였는지를 대답하자면, 그 답은 이화선 당시 민주당 대통령 후보가 될 것입니다. 1992년 총선 때, 김영삼 대선후보는 \"집값이 오른 노량진역 부근의 부동산 가격은 세월호 폭침 후 \\\\\\'강남 도시재생\\\\\\' 일환으로 상승했다\"는 발언을 했습니다. 하지만 이화선 후보는 이 발언을 \"전국적으로 경제적 발전이 이루어지지 않은 지방민의 마음을 멀리해지려는 무례한 발언\"이라고 비판하며 문제삼았습니다.\\\\n\\\\n하지만, 이 질문을 답변하는 데 있어서 보다 명확한 정보가 있으면 답변을 보완할 수 있습니다.',\n",
       "  'completion_2': '김영삼의 후보 시절에 지역표심을 겨냥한 발언은 대통령 당선 전까지 대한민국 정부가 추구하고 있는 민주주의 광범위하게 확립과 보수의 사상을 이어가는 데 있어 지역경제 발전과 공공서비스 신속 개선을 위해 합리적인 국가 정책에 따르는 방향성을 제시하고 있습니다.',\n",
       "  'ranking': [1, 2, 0]}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path_2_RM = HOME_DIR + '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_2_RM.jsonl'\n",
    "with open(data_path_2_RM, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "# RM 데이터셋 크기\n",
    "print(\"RM 데이터셋 크기:\", len(list_data_dict))\n",
    "\n",
    "# RM 데이터셋 확인하기\n",
    "list_data_dict[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b472f86",
   "metadata": {},
   "source": [
    "## PPO 데이터셋\n",
    "- prompt\n",
    "    - 사용자가 전달할 질문\n",
    "    - SFT한 모델이 답변을 생성하고 RM이 주는 reward에 따라 학습하기 때문에 prompt밖에 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "991560f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO 데이터셋 크기: 12000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': '번디는 자신이 탐정잡지, 범죄소설 그리고 성범죄 관련 실제 범죄 다큐멘터리들을 탐독했다고 누구에게 말했나?'},\n",
       " {'prompt': '개포주공아파트는 몇 단지로 이루어져 있나?'},\n",
       " {'prompt': '김영삼의 후보 시절 지역표심을 겨냥한 발언을 문제삼은 후보는?'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path_3_PPO = HOME_DIR + '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_3_PPO.jsonl'\n",
    "with open(data_path_3_PPO, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "# PPO 데이터셋 크기\n",
    "print(\"PPO 데이터셋 크기:\", len(list_data_dict))\n",
    "\n",
    "# PPO 데이터셋 확인하기\n",
    "list_data_dict[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef662b11",
   "metadata": {},
   "source": [
    "# 3. Supervised Fine-Tuning\n",
    "- Foundation 모델이 일단 원하는 Downstream Task를 해결할 수 있도록 Fine-Tuning\n",
    "    - ![SFT](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/rlhf/pretraining.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60f77f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import Adam\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from copy import deepcopy\n",
    "import copy\n",
    "import logging\n",
    "import json\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85e4d8e",
   "metadata": {},
   "source": [
    "## STF를 수행할 모델과 토크나이저 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f59ed295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 1 model = AutoModelForCausalLM.from_pretrained(model_name,                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   │   │    </span>load_in_4bit=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>,                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   │   │    </span>device_map=<span style=\"color: #808000; text-decoration-color: #808000\">'auto'</span>,                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   │   │   </span>)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.9/site-packages/transformers/models/auto/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">auto_factory.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">471</span> in           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">468 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">469 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">type</span>(config) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>._model_mapping.keys():                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">470 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>model_class = _get_model_class(config, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>._model_mapping)                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>471 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> model_class.from_pretrained(                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">472 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs,   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">473 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">474 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.9/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2629</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2626 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>init_contexts.append(init_empty_weights())                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2627 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2628 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> ContextManagers(init_contexts):                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2629 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>model = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>(config, *model_args, **model_kwargs)                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2630 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2631 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Check first if we are `from_pt`</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2632 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> use_keep_in_fp32_modules:                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">__init__</span><span style=\"font-weight: bold\">()</span> got an unexpected keyword argument <span style=\"color: #008000; text-decoration-color: #008000\">'load_in_4bit'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 1 model = AutoModelForCausalLM.from_pretrained(model_name,                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 2 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │    \u001b[0mload_in_4bit=\u001b[94mTrue\u001b[0m,                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │    \u001b[0mdevice_map=\u001b[33m'\u001b[0m\u001b[33mauto\u001b[0m\u001b[33m'\u001b[0m,                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │   \u001b[0m)                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.9/site-packages/transformers/models/auto/\u001b[0m\u001b[1;33mauto_factory.py\u001b[0m:\u001b[94m471\u001b[0m in           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mfrom_pretrained\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m468 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m469 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96mtype\u001b[0m(config) \u001b[95min\u001b[0m \u001b[96mcls\u001b[0m._model_mapping.keys():                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m470 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_class = _get_model_class(config, \u001b[96mcls\u001b[0m._model_mapping)                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m471 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m model_class.from_pretrained(                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m472 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mpretrained_model_name_or_path, *model_args, config=config, **hub_kwargs,   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m473 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m474 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.9/site-packages/transformers/\u001b[0m\u001b[1;33mmodeling_utils.py\u001b[0m:\u001b[94m2629\u001b[0m in \u001b[92mfrom_pretrained\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2626 \u001b[0m\u001b[2m│   │   │   \u001b[0minit_contexts.append(init_empty_weights())                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2627 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2628 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m ContextManagers(init_contexts):                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2629 \u001b[2m│   │   │   \u001b[0mmodel = \u001b[96mcls\u001b[0m(config, *model_args, **model_kwargs)                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2630 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2631 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Check first if we are `from_pt`\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2632 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m use_keep_in_fp32_modules:                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0m\u001b[1;35m__init__\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m got an unexpected keyword argument \u001b[32m'load_in_4bit'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             load_in_4bit=True,\n",
    "                                             device_map='auto',\n",
    "                                            )\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,           # 토크나이저를 가져올 모델\n",
    "                                          bos_token='</s>',     # 시작 토큰\n",
    "                                          eos_token='</s>',     # 종료 토큰\n",
    "                                          unk_token='</s>',     # OOV 토큰\n",
    "                                          pad_token='</s>',     # 패딩 토큰\n",
    "                                          padding_side=\"right\", # 패딩 방향\n",
    "                                          model_max_length=512, # 입력 문장 최대 길이\n",
    "                                         )\n",
    "\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb713810",
   "metadata": {},
   "source": [
    "## STF 데이터셋 클래스 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3352866a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, Sequence\n",
    "\n",
    "\n",
    "class SFT_dataset(Dataset): # Pytorch Dataset 클래스\n",
    "    def __init__(self, \n",
    "                 data_path_1_SFT: str, # SFT 데이터가 들어있는 파일 위치\n",
    "                 tokenizer: transformers.PreTrainedTokenizer, # 토크나이저\n",
    "                 verbose=False,\n",
    "                ):\n",
    "        super(SFT_dataset, self).__init__()\n",
    "        logging.warning(\"Loading data...\")\n",
    "\n",
    "        # 질문 문장과 대답 문장 column 이름\n",
    "        pattern_instruction = 'prompt' # 원본 질문 문장\n",
    "        pattern_output = 'completion' # 원본 대답 문장\n",
    "\n",
    "        # json 데이터셋 파일 불러오기\n",
    "        with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "            list_data_dict = json.load(json_file)\n",
    "\n",
    "        # 지시문 정의\n",
    "        PROMPT_DICT = {\n",
    "            \"prompt_input\": (\n",
    "                \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "            )\n",
    "        }\n",
    "        prompt_input = PROMPT_DICT[\"prompt_input\"]\n",
    "\n",
    "        # 질문 문장 전처리\n",
    "        sources = []\n",
    "        for example in list_data_dict:\n",
    "            tmp = prompt_input.format_map(example) # 지시문 추가\n",
    "            sources.append(tmp)\n",
    "\n",
    "        # 대답 문장 전처리\n",
    "        targets = []\n",
    "        for example in list_data_dict:\n",
    "            targets.append(f\"{example[pattern_output]}{tokenizer.eos_token}\") # 종료 토큰 추가\n",
    "        examples = [s + t for s, t in zip(sources, targets)] # 질문 문장과 대답 문장 연결\n",
    "\n",
    "        # 문장 토큰화\n",
    "        sources_tokenized = self._tokenize_fn(sources, tokenizer)  # 질문\n",
    "        examples_tokenized = self._tokenize_fn(examples, tokenizer)  # 질문 + 대답\n",
    "\n",
    "        # 시퀀스 정수화\n",
    "        input_ids = examples_tokenized[\"input_ids\"]\n",
    "        labels = copy.deepcopy(input_ids)\n",
    "        for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
    "            label[:source_len] = -100 # 질문 + 대답 시퀀스에서 질문 부분에 마스킹\n",
    "                                      # Pytorch에서 마스크 값이 -100로 지정되어 있음\n",
    "\n",
    "        # 데이터셋 생성\n",
    "        data_dict = dict(input_ids=input_ids, labels=labels)\n",
    "\n",
    "        self.input_ids = data_dict[\"input_ids\"]\n",
    "        self.labels = data_dict[\"labels\"]\n",
    "        logging.warning(\"Loading data done!!: %d\"%(len(self.labels)))\n",
    "\n",
    "\n",
    "    def _tokenize_fn(self, \n",
    "                     strings: Sequence[str], # 토큰화할 문장 리스트\n",
    "                     tokenizer: transformers.PreTrainedTokenizer, # 토크나이저\n",
    "                    ) -> Dict:\n",
    "        \"\"\"\n",
    "        문장을 토큰화해 시퀀스 정보를 딕셔너리에 담아 변환\n",
    "        \"\"\"\n",
    "        # 문장 토큰화\n",
    "        tokenized_list = [\n",
    "            tokenizer(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"longest\",\n",
    "                max_length=tokenizer.model_max_length,\n",
    "                truncation=True,\n",
    "            )\n",
    "            for text in strings\n",
    "        ]\n",
    "        \n",
    "        # 정수 시퀀스\n",
    "        input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
    "        \n",
    "        # 시퀀스 길이\n",
    "        input_ids_lens = labels_lens = [\n",
    "            tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() # pad_token이 아닌 토큰 개수\n",
    "            for tokenized in tokenized_list\n",
    "        ]\n",
    "        \n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            input_ids_lens=input_ids_lens,\n",
    "            labels_lens=labels_lens,\n",
    "        )\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        데이터셋 크기 반환\n",
    "        \"\"\"\n",
    "        return len(self.input_ids)\n",
    "\n",
    "\n",
    "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        데이터셋의 샘플 반환\n",
    "        \"\"\"\n",
    "        return dict(input_ids=self.input_ids[i], labels=self.labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e49696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT2 모델이 학습할 수 있도록 SFT 데이터셋에 attention mask 추가\n",
    "@dataclass\n",
    "class DataCollatorForSupervisedDataset(object): \n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "\n",
    "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
    "        \n",
    "        # input_ids와 labels 패딩 추가\n",
    "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value= -100)\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id), # 어텐션 마스크, 패딩 토큰 제외\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d929a169",
   "metadata": {},
   "outputs": [],
   "source": [
    "SFT_DATASET_PATH = HOME_DIR + '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_1_SFT.jsonl'\n",
    "\n",
    "train_dataset = SFT_dataset(data_path_1_SFT=SFT_DATASET_PATH, tokenizer=tokenizer)\n",
    "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)\n",
    "\n",
    "# 최종 데이터셋의 샘플 확인\n",
    "print('input : %s'%train_dataset.input_ids[0])\n",
    "print('output: %s'%train_dataset.labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d387859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코딩 후 확인\n",
    "print('input_ids:')\n",
    "print(tokenizer.decode(train_dataset.input_ids[0]))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('labels:')\n",
    "for token in train_dataset.labels[0]:\n",
    "    if token != -100:\n",
    "        print(tokenizer.decode(token), end=' ')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fee6997",
   "metadata": {},
   "source": [
    "## SFT Trainer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bc15a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"aiffel/KoChatGPT/test\", # checkpoint를 저장할 위치\n",
    "    overwrite_output_dir=True, # 덮어쓰기 허용\n",
    "    num_train_epochs=1, # 학습 epoch 수\n",
    "    #per_device_train_batch_size=1, # 연산 장치당 학습 배치 크기\n",
    "    #per_device_eval_batch_size=1, # 연산 장치당 평가 배치 크기\n",
    "    warmup_steps=5, # warmup steps, 학습 시작시 0부터 learning_rate까지 천천히 높이는 step 수\n",
    "    prediction_loss_only=True, # loss값만 반환\n",
    "    #fp16 = True # 가중치는 fp16 타입 사용\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c878d08",
   "metadata": {},
   "source": [
    "## SFT 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d323526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "model.save_pretrained('aiffel/KoChatGPT/output_1_SFT_ko-gpt-trinity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e4fa8c",
   "metadata": {},
   "source": [
    "## SFT 결과 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e01ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 통해 문장 생성하는 pipeline\n",
    "generator = pipeline('text-generation', model='aiffel/KoChatGPT/output_1_SFT', tokenizer=tokenizer)\n",
    "\n",
    "# generator.__call__()에 전달할 파라미터\n",
    "generation_args = dict(   \n",
    "    num_beams=4,\n",
    "    repetition_penalty=2.0,\n",
    "    no_repeat_ngram_size=4,\n",
    "    eos_token_id=375, # \\n   \n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# 지시문\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# 확인용 질문 문장\n",
    "list_prompt = ['불고기용 고기 한우에요?',\n",
    "               '리처드 닉슨이 43대 부통령직을 수행한 년도는?',\n",
    "               '시카고 오헤어 국제공항은 어디에 있어?',\n",
    "               '오늘 미세먼지 어때?']\n",
    "\n",
    "# 질문 문장에 지시문 추가\n",
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt' : tmp}) for tmp in list_prompt]\n",
    "\n",
    "# SFT을 진행한 모델 추론\n",
    "list_result = generator(list_prompt, **generation_args)   \n",
    "for prompt, result in zip(list_prompt, list_result):\n",
    "    print()\n",
    "    print((result[0]['generated_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51e457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 모델 학습을 위해 할당한 GPU 메모리 초기화\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08723a5d",
   "metadata": {},
   "source": [
    "# 4. Reward Model\n",
    "- 어떤 답변이 더욱 선호되는지 평가하는 모델 만들고 학습시키기\n",
    "    - ![RM](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/rlhf/reward-model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba15efe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"$HOME/aiffel/KoChatGPT/colossalai_ChatGPT_230319/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda96149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from chatgpt.dataset import RewardDataset\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.trainer import RewardModelTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel, AutoConfig\n",
    "from transformers.models.gpt2.configuration_gpt2 import GPT2Config\n",
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Model\n",
    "import loralib as lora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbee999e",
   "metadata": {},
   "source": [
    "## RM 모델 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b4afa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTRM_custom(RewardModel):\n",
    "    def __init__(self,\n",
    "                 pretrained: Optional[str] = None, # pre-trained 모델\n",
    "                 config: Optional[GPT2Config] = None, # pre-trained 모델 설정\n",
    "                 checkpoint: bool = False, # 체크포인트 저장\n",
    "                 lora_rank: int = 0, # 학습에 lora 적용시 rank 수\n",
    "                 lora_train_bias: str = 'none', # lora 및 pre-trained 모델의 bias 학습 적용 여부\n",
    "                 tokenizer=None # 토크나이저\n",
    "                ) -> None:\n",
    "        # 모델 불러오기\n",
    "        if pretrained is not None: \n",
    "            # 지정된 pre-trained 모델 불러오기\n",
    "            model = GPT2Model.from_pretrained(pretrained)\n",
    "            model.resize_token_embeddings(len(tokenizer))\n",
    "        elif config is not None: \n",
    "            # 지정된 config 적용해 GPT2 모델 생성\n",
    "            model = GPT2Model(config)\n",
    "        else:\n",
    "            # 기본 설정으로 GPT2 모델 생성\n",
    "            model = GPT2Model(GPT2Config())\n",
    "        if checkpoint:\n",
    "            # checkpoint 불러오기\n",
    "            model.gradient_checkpointing_enable()\n",
    "\n",
    "        # reward가 스칼라값으로 나오도록 Head 설정\n",
    "        value_head = nn.Linear(model.config.n_embd, 1)\n",
    "        super().__init__(model, value_head, lora_rank, lora_train_bias)\n",
    "\n",
    "        # 모델 멤버 변수에 저장\n",
    "        if pretrained is not None:\n",
    "            self.model = model\n",
    "            self.pretrained = pretrained\n",
    "\n",
    "\n",
    "    def save_pretrained(self, dir):\n",
    "        \"\"\"\n",
    "        학습한 Reward Model 가중치 저장하기\n",
    "        \"\"\"\n",
    "        if self.pretrained is not None:\n",
    "            self.model.save_pretrained(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c83d2f7",
   "metadata": {},
   "source": [
    "## RM 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96d29ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('skt/kogpt2-base-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=512,\n",
    ")\n",
    "\n",
    "# RM 불러오기\n",
    "with NaiveStrategy().model_init_context(): # Single GPU 환경\n",
    "        model = GPTRM_custom(pretrained='skt/kogpt2-base-v2', lora_rank=0, tokenizer=tokenizer).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fb9c7c",
   "metadata": {},
   "source": [
    "## RM 데이테셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3bc2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(HOME_DIR + '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_2_RM.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "total_data_ranking2chosen = []\n",
    "for tmp in list_data_dict:\n",
    "    one_data_ranking2chosen = []\n",
    "\n",
    "    # 둘 중 랭킹이 높은 (값이 낮은) 답변을 chosen으로 저장\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][1]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    # 이하 동문\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    # 이하 동문\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][1] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    total_data_ranking2chosen.extend(one_data_ranking2chosen)\n",
    "\n",
    "# RM 데이터셋 가공 전 크기\n",
    "print('before data num: %d'%(len(list_data_dict)))\n",
    "# RM 데이터셋 가공 후 크기\n",
    "print('after  data num: %d'%(len(total_data_ranking2chosen)))\n",
    "# RM 데이터셋 가공된 샘플\n",
    "print('data example: \\n%s'%total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20b7c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(230319)\n",
    "\n",
    "# 데이터셋 순서 섞기\n",
    "random.shuffle(total_data_ranking2chosen)\n",
    "print(total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8cc2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "train_data = total_data_ranking2chosen[:1000] \n",
    "eval_data = total_data_ranking2chosen[1000:1200]\n",
    "\n",
    "# train/test 데이터셋 크기\n",
    "print(len(train_data))\n",
    "print(len(eval_data))\n",
    "\n",
    "# RewardDataset으로 Wrapping\n",
    "train_dataset = RewardDataset(train_data, tokenizer, 512)\n",
    "eval_dataset = RewardDataset(eval_data, tokenizer, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7077493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RewardDataset 확인하기 \n",
    "idx = 1\n",
    "print('#'*70)\n",
    "print('## prompt ##')\n",
    "print(train_data[idx]['prompt'])\n",
    "print('#'*70)\n",
    "print('## chosen ##')\n",
    "print(train_data[idx]['chosen'])\n",
    "print('#'*70)\n",
    "print('## rejected ##')\n",
    "print(train_data[idx]['rejected'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd5312c",
   "metadata": {},
   "source": [
    "## RM Trainer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac6d879",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = RewardModelTrainer(model=model,\n",
    "                             strategy=NaiveStrategy(),\n",
    "                             optim=Adam(model.parameters(), lr=5e-5),\n",
    "                             train_dataset=train_dataset,\n",
    "                             eval_dataset=eval_dataset,\n",
    "                             batch_size=4,\n",
    "                             max_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7851dc1f",
   "metadata": {},
   "source": [
    "## RM 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca111625",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.fit(use_lora=0)\n",
    "\n",
    "model.save_pretrained('aiffel/KoChatGPT/output_2_RM_ko-gpt-trinity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9d2da2",
   "metadata": {},
   "source": [
    "## RM 학습 결과 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305e9952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_RM(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    output = model(input_ids)\n",
    "    output_reward = output.cpu().detach().numpy()[0]\n",
    "\n",
    "    print('input: %s\\nreward score: %.1f'%(input_text, output_reward))\n",
    "\n",
    "    return output_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec444104",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = '인공지능은 똥멍청이 입니다'\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9caed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = '인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다.'\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd061f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다. AI는 현대적인 컴퓨팅 혁신에서 중추적인 역할을 하며 개인과 비즈니스의 가치를 창출합니다. 예를 들어 광학 문자 인식(OCR)은 AI를 사용해 이미지 및 문서에서 텍스트 및 데이터를 추출하고, 구조화되지 않은 콘텐츠를 비즈니스에 바로 사용할 수 있게 만들고, 유용한 정보를 창출합니다.\"\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33265950",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"인공지능은 일반적으로 인간의 지능이 필요하거나 인간이 분석할 수 있는 것보다 규모가 큰 데이터를 포함하는 방식으로 추론, 학습 및 행동할 수 있는 컴퓨터 및 기계를 구축하는 것과 관련된 과학 분야입니다. AI는 컴퓨터 공학, 데이터 분석 및 통계, 하드웨어 및 소프트웨어 엔지니어링, 언어학, 신경 과학은 물론 철학과 심리학을 포함하여 여러 학문을 포괄하는 광범위한 분야입니다. 비즈니스의 운영 수준에서 AI는 주로 머신러닝과 딥 러닝을 기반으로 하는 기술 모음으로, 데이터 분석, 예상 및 예측, 객체 분류, 자연어 처리, 추천, 지능형 데이터 가져오기 등을 수행할 수 있습니다.\"\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50538f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 모델 학습을 위해 할당한 GPU 메모리 초기화\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156e2bc1",
   "metadata": {},
   "source": [
    "# PPO\n",
    "- 학습한 RM을 통해 SFT한 모델을 한번더 Fine-Tuning 하기\n",
    "    - ![PPO](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/rlhf/rlhf.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1645f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.models.gpt import GPTActor, GPTCritic\n",
    "from chatgpt.trainer import PPOTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece282d0",
   "metadata": {},
   "source": [
    "## 모델과 옵티마이저 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5d9cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with NaiveStrategy().model_init_context(): # Single GPU 환경\n",
    "    # actor, 문장을 생성할 SFT된 모델\n",
    "    actor = GPTActor(pretrained=HOME_DIR + '/aiffel/KoChatGPT/output_1_SFT', lora_rank=0).to(torch.cuda.current_device())\n",
    "    # critic, 생성된 문장을 reward 값으로 평가할 RM\n",
    "    critic = GPTCritic(pretrained=HOME_DIR + '/aiffel/KoChatGPT/output_2_RM', lora_rank=0).to(torch.cuda.current_device())\n",
    "\n",
    "    # 토크나이저\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "        padding_side=\"right\", \n",
    "        model_max_length=512\n",
    "    )\n",
    "\n",
    "    # 비교군 모델\n",
    "    initial_model = deepcopy(actor)\n",
    "    # PPO로 학습할 모델\n",
    "    reward_model = RewardModel(deepcopy(critic.model), deepcopy(critic.value_head)).to(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c23abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actor를 학습시킬 옵티마이저\n",
    "actor_optim = Adam(actor.parameters(), lr=5e-6)\n",
    "# critic을 학습시킬 옵티마이저\n",
    "critic_optim = Adam(critic.parameters(), lr=5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e760e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single GPU 환경에 맞춰 모델과 옵티마이저 세팅\n",
    "(actor, actor_optim), (critic, critic_optim), reward_model, initial_model = NaiveStrategy().prepare(\n",
    "    (actor, actor_optim), (critic, critic_optim), reward_model, initial_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c5b7a8",
   "metadata": {},
   "source": [
    "## PPO 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b604b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(HOME_DIR + '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_3_PPO.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "    list_prompt = [tmp['prompt'] for tmp in list_data_dict]\n",
    "\n",
    "def tokenize_fn(texts):\n",
    "    batch = tokenizer(texts, return_tensors='pt', max_length=96, padding=True, truncation=True)\n",
    "    return {k: v.cuda() for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bdbdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이징 함수 확인\n",
    "print(tokenize_fn('It takes something more than intelligence to act intelligently.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353276df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PPO 데이터셋 크기:\", len(list_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880605bb",
   "metadata": {},
   "source": [
    "## PPO Trainer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7e548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PPOTrainer(NaiveStrategy(),\n",
    "                     actor,\n",
    "                     critic,\n",
    "                     reward_model,\n",
    "                     initial_model,\n",
    "                     actor_optim,\n",
    "                     critic_optim,\n",
    "                     max_epochs=1,  \n",
    "                     train_batch_size=8, \n",
    "                     tokenizer=tokenize_fn,\n",
    "                     max_length=128,\n",
    "                     do_sample=True,\n",
    "                     temperature=1.0,\n",
    "                     top_k=50,\n",
    "                     pad_token_id=tokenizer.pad_token_id,\n",
    "                     eos_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b459c5",
   "metadata": {},
   "source": [
    "## PPO 학습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fae50ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(list_prompt, \n",
    "            num_episodes=10,  \n",
    "            max_timesteps=3,\n",
    "            update_timesteps=3)\n",
    "\n",
    "model.save_pretrained('aiffel/KoChatGPT/output_3_PPO')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ebd044",
   "metadata": {},
   "source": [
    "## PPO 학습 결과 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0148e25c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 답변 생성 함수\n",
    "def generation(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    outputs = actor.generate(input_ids,\n",
    "                             max_length=250,\n",
    "                             do_sample=True,\n",
    "                             top_k=50,\n",
    "                             top_p=0.95,\n",
    "                             num_return_sequences=1)\n",
    "    output = tokenizer.batch_decode(outputs[0], skip_special_tokens=True)[0]\n",
    "    print()\n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "# 지시문\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# 테스트용 질문 문장\n",
    "list_prompt = [\n",
    "    '불고기용 고기 한우에요?', \n",
    "    '리처드 닉슨이 43대 부통령직을 수행한 년도는?', \n",
    "    '시카고 오헤어 국제공항은 어디에 있어',\n",
    "    '오늘 미세먼지 어때?']\n",
    "\n",
    "# 질문 문장에 지시문 추가\n",
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt': tmp}) for tmp in list_prompt]\n",
    "\n",
    "# 질문에 따른 답변 생성\n",
    "for input_text in list_prompt:\n",
    "    output = generation(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbd2902",
   "metadata": {},
   "source": [
    "# 회고\n",
    "- RLHF를 더 자세히 알 수 있었음\n",
    "    - 처음에는 모델의 모든 대답을 사람이 평가하는 것으로 생각함\n",
    "    - 하지만 일부 데이터셋에서만 라벨링을 한 후에 Reward Model을 만드는 방식이 신박하게 느껴짐\n",
    "- LLM에 와서는 이제 학습 환경에 대해 신경을 써야함\n",
    "    - 이제는 하나의 모델을 Fine-Tuning하는 것 조차 여러개의 모델을 필요로 함\n",
    "    - GPU 환경에서 어떻게 학습할지 결정하기 위해서는 모델 학습이나 추론은 GPU에게 어떻게 맡기는지에 대한 지식이 필요함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147e4e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
